### Mini Description

Techniques to make self-modification or generation of successors to be more goal-stable

### Description

Sufficiently advanced agents may modify themselves. Doing so in a stable manner and without leading to detrimental directions is a challenge ([Soares and Fallenstein 2014a](http://intelligence.org/files/TechnicalAgenda.pdf)). Though very difficult to get right, there are some techniques to help make self-modification or generation of successors to be more goal-stable. Early attempts at making this safer leverage extensive introspection and value-based prioritization ([Nivel et al. 2013](http://people.idsia.ch/~steunebrink/Publications/TR13_bounded_recursive_self-improvement.pdf), [Steunebrink et al. 2016](http://people.idsia.ch/~steunebrink/Publications/AGI16_growing_recursive_self-improvers.pdf), [Steunebrink 2016](https://intelligence.org/files/csrbai/steunebrink-slides.pdf)). But because this self-improvement dynamic can snowball, one would like stronger assurances around safety ([Soares and Fallenstein 2014a](http://intelligence.org/files/TechnicalAgenda.pdf)).

### Related Nodes

- [Controlling Another Algorithm](/Value_Alignment/Control/Oversight/Controlling_Another_Algorithm/Controlling_Another_Algorithm.md)
	- Reason: From Safer Self-Modification also see Controlling Another Algorithm as "self" modification tasks are sometimes interested in creating successor agents or alternatively subagents, which should typically be subject to control.
- [Verification of Recursive Self-Improvement](/Value_Alignment/Verification/Verification_of_Recursive_Self-Improvement/Verification_of_Recursive_Self-Improvement.md)
