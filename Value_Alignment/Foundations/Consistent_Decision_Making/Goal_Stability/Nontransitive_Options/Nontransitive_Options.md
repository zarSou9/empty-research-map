### Mini Description

How to maintain stability of goals, objectives, and actions in the presence of options or preferences that are cyclic or nontransitive

### Description

Whether individual operators, an aggregation of values of a large number of humans, or potentially the agent itself can have nontransitive preferences, where cycles or loops of comparative preferences occur ([Dombi and Vincze 1994](http://www.sciencedirect.com/science/article/pii/0165489694007357)). While some approaches seek to eliminate such a situation before it arises, more fault-tolerant approaches will attempt to handle such cycles gracefully ([Nishimura and Ok 2016](http://hirokinishimura.net/files/BinRelRep.pdf)), and this is an open area of research. It is conceivable that solutions to problems like low impact and corrigibility will result in agents that violate one or more Von Neumann-Morgenstern axioms (Taylor 2016b), and neuromorphic architectures such as the common deep learning architectures of the day, will almost certainly violate them. The challenge is to do this in a way that's reflectively stable, having the agent not want to rewrite itself into a different agent, and still allows the agent to have a sensible world model. Minimax decision rules are one plausible variant where this can hold (Taylor 2016b).

### Related Nodes

- [Multiobjective Optimization](/Value_Alignment/Validation/Averting_Instrumental_Incentives/Domesticity/Mild_Optimization/Multiobjective_Optimization/Multiobjective_Optimization.md)
