### Mini Description

Theories of reasoning that use alternate interpretations, alternate histories, and hypothetical scenarios to disambiguate and to find optimal actions

### Description

One key open question in foundational rationality is what theory of counterfactual reasoning can be used to specify a procedure which always identifies the best action available to a given agent in a given environment, with respect to a given set of preferences ([Soares and Fallenstein 2015](https://pdfs.semanticscholar.org/40b3/bbe8d3e0ff66caae3217f4b2fc0e71fd01e2.pdf), [Critch 2016](http://acritch.com/media/ai/Andrew_Critch_-_Parametric_Bounded_Lob.pdf), [Soares and Fallenstein 2014a](http://intelligence.org/files/TechnicalAgenda.pdf)).

### Related Nodes

- [Counterfactual Reasoning](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Uncertainty_Identification_and_Management/Inductive_Ambiguity_Identification/Robustness_to_Distributional_Shift/Counterfactual_Reasoning/Counterfactual_Reasoning.md)
	- Reason: From Theory of Counterfactuals also see Counterfactual Reasoning regarding drift detection in induction.
- [Logical Counterfactuals](/Value_Alignment/Foundations/Consistent_Decision_Making/Decision_Theory/Logical_Counterfactuals/Logical_Counterfactuals.md)
- [Goal Stability](/Value_Alignment/Foundations/Consistent_Decision_Making/Goal_Stability/Goal_Stability.md)
- [Avoiding Reward Hacking](/Value_Alignment/Validation/Avoiding_Reward_Hacking/Avoiding_Reward_Hacking.md)
- [Averting Instrumental Incentives](/Value_Alignment/Validation/Averting_Instrumental_Incentives/Averting_Instrumental_Incentives.md)
- [Increasing Contextual Awareness](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Increasing_Contextual_Awareness.md)
- [Verification](/Value_Alignment/Verification/Verification.md)
- [Security](/Value_Alignment/Security/Security.md)
- [Oversight](/Value_Alignment/Control/Oversight/Oversight.md)
- [Computational Deference](/Value_Alignment/Control/Computational_Deference/Computational_Deference.md)
- [Technical Value Alignment](/Value_Alignment/Validation/Technical_Value_Alignment/Technical_Value_Alignment.md)
- [Value Interrogation](/Value_Alignment/Validation/Technical_Value_Alignment/Ethics_Mechanisms/Value_Learning/Value_Elicitation/Value_Interrogation/Value_Interrogation.md)
