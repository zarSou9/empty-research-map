### Mini Description

Building and using containers where tests on powerful agents can be done safely and reliably

### Description

Since generally intelligent agents represent varied and storied risks, it is prudent to test such agents in a confined environment ([Russell et al. 2015](http://futureoflife.org/data/documents/research_priorities.pdf)) before releasing them into the wild. Building and using containers where such tests on powerful agents can be done safely and reliably ([Yampolskiy 2012](http://cecs.louisville.edu/ry/LeakproofingtheSingularity.pdf), [Babcock et al. 2016](https://pdfs.semanticscholar.org/d7a4/adb20a879e89fc12600c84dff0cb69fd7d58.pdf)) is challenging, and must account for operator psychology. If general containment proves too difficult, it may be wise to designing the AI and a specialized container for it in parallel  ([Bostrom 2014](https://global.oup.com/academic/product/superintelligence-9780199678112)).

### Related Nodes

- [Careful Engineering](/Value_Alignment/Validation/Avoiding_Reward_Hacking/Careful_Engineering/Careful_Engineering.md)
