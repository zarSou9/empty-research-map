### Mini Description

In cases where it is unclear which subset of operators to be loyal to, modeling the intent of each operator and biasing to those most value-aligned if value alignment has already occurred to an acceptable degree

### Description

In use cases where it is unclear which subset of operators ([Neff and Nagy 2016](http://ijoc.org/index.php/ijoc/article/viewFile/6277/1804)) to be loyal to ([Pistono and Yampolskiy 2016](https://arxiv.org/ftp/arxiv/papers/1605/1605.02817.pdf)), it may be proper to model the intent of each operator ([Probst and Kasera 2007](http://www.cs.utah.edu/~kasera/myPapers/trust.pdf)) and bias to those that reflect values ([Rossi 2016a](https://intelligence.org/files/csrbai/pref-eth1.pdf)) present in the agent ([Steunebrink et al. 2016](http://people.idsia.ch/~steunebrink/Publications/AGI16_growing_recursive_self-improvers.pdf)) after successful value alignment ([Soares 2016](https://intelligence.org/files/ValueLearningProblem.pdf)).

### Related Nodes

- [Misuse Risk](/Value_Alignment/Security/Misuse_Risk/Misuse_Risk.md)
