### Mini Description

Encompasses ethical systems which focus on the consequences of actions as being the ground by which an action is determined to be ethical or unethical.

### Description

It is unclear whether a purely consequentialist approach to AI ethics is, by itself, a viable solution to value alignment. This is due to the potential computational intractability of accounting for complex systems and large amounts of causes and conditions that lead to various outcomes. In response to this, parameters can be set to limit the extent to which an AI dedicates resources to computing possible outcomes and their likelihoods.This can be done through intelligent heuristics that set rational boundaries for time spent on reflection and may thus help with cutting down on computational complexity (Wallach 2007). Furthermore, some forms of consequentialism may be more viable than others, such as two-level utilitarianism and rule utilitarianism as they are the formalization of commitment to, at least in part, higher level principles and generalized rules that can be shared and learned relatively easily. When an agent is able to act or participate in morality based on previously agreed upon or discovered and formulated rules or maxims, said agent cuts down on computational requirements by avoiding the need to continuously take into account all relevant and even possible consequences of actions in new situations.

There will be cases where purely consequentialist accounts of what ought to be done will be far more tractable, such as with big data driven bioethics in resource limited contexts. In the end, it may also be the case that some mixture of virtue ethics, consequentialism, deontological ethics, and unknown ethical structures will be ideal as they are each more or less computationally efficient in different domains. There has been very little research regarding the computational viability of and means of computerizing top-down approaches (Wallach 2007).
