### Mini Description

Using adversarial learning techniques to blind a model to the effects of certain variables, useful for masking how an agent's reward is generated to make it difficult to hack

### Description

Adversarial techniques can be used to blind a model to certain variables, useful for masking how an agent's reward is generated, and enabling cross-validation for agents ([Amodei et al. 2016](http://arxiv.org/abs/1606.06565), [Ganin et al. 2016](http://jmlr.org/papers/volume17/15-239/15-239.pdf)).
