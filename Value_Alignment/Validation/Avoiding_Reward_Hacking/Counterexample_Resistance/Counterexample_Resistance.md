### Mini Description

Reducing susceptibility to adversarial tricks via adversarial training

### Description

One might design a system to build resistance ([Amodei et al. 2016](http://arxiv.org/abs/1606.06565)) to natural and unnatural counterexamples, confounding patterns, and adversarial tricks by leveraging adversarial training ([Goodfellow et al. 2015](https://pdfs.semanticscholar.org/bee0/44c8e8903fb67523c1f8c105ab4718600cdb.pdf), [Blundell et al. 2015](http://jmlr.org/proceedings/papers/v37/blundell15.pdf), [Fathony et al. 2016](http://papers.nips.cc/paper/6088-adversarial-multiclass-classification-a-risk-minimization-perspective.pdf)). This discourages the agent from purturbing its data to achieve alternate interpretations.

### Related Nodes

- [Adversarial ML](/Value_Alignment/Security/Handling_Improper_External_Behavior/Adversarial_ML/Adversarial_ML.md)
	- Reason: From Counterexample Resistance also see Adversarial ML as this can also be framed as a security issue when external parties are providing the adversarial testing or production data.
