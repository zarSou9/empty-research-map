### Mini Description

Directly or slightly indirectly specifying values a system should hold and act on

### Description

Broadly, value specification is the direct or somewhat indirect specifying of values a system should hold and act on. The intentions of operators are, however, fuzzy, not well-specified, and sometimes containing contradictions ([Yudkowsky 2011](http://dx.doi.org/10.1007/978-3-642-22887-2_48)). Some prominent AI researchers expect moral philosophy to become an increasingly important commercial industry ([Russell 2016](http://time.com/4026723/stuart-russell-will-ai-overtake-humans/)). With advanced agents, it's not sufficient to develop a system intelligent enough to figure out the intended goals, though; the system must also somehow be deliberately constructed to pursue them ([Bostrom 2014](https://global.oup.com/academic/product/superintelligence-9780199678112), [Soares and Fallenstein 2014a](http://intelligence.org/files/TechnicalAgenda.pdf)).

### Related Nodes

- [Multilevel World-Models](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Concept_Geometry/Multilevel_World-Models/Multilevel_World-Models.md)
- [Uncertainty Identification and Management](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Uncertainty_Identification_and_Management/Uncertainty_Identification_and_Management.md)
- [Operator Modeling](/Value_Alignment/Validation/Technical_Value_Alignment/Robust_Human_Imitation/Operator_Modeling/Operator_Modeling.md)
- [Normative Uncertainty](/Value_Alignment/Ethics/Metaethics/Ethical_uncertainty/Normative_Uncertainty/Normative_Uncertainty.md)
- [Value Interrogation](/Value_Alignment/Validation/Technical_Value_Alignment/Ethics_Mechanisms/Value_Learning/Value_Elicitation/Value_Interrogation/Value_Interrogation.md)
