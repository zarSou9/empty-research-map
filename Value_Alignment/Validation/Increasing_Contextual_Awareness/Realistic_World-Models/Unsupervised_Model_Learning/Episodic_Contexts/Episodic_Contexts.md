### Mini Description

Mining historical or live episodes for hints to defining states and concepts

### Description

In model-based reinforcement learning, one can use the observed transitions of the unlabeled episodes to improve the quality of the model ([Amodei et al. 2016](http://arxiv.org/abs/1606.06565), [Andre and Russell 2002](https://people.eecs.berkeley.edu/~russell/papers/aaai02-alisp.pdf)). State abstraction from either online or offline episodes using similar such techniques can also be applied in other model learning paradigms ([Yang et al. 2015](https://www.umiacs.umd.edu/~yzyang/paper/YouCookMani_CameraReady.pdf)).
