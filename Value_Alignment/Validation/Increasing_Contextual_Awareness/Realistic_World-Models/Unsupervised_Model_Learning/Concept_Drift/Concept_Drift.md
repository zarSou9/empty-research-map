### Mini Description

The unforeseen movement of the boundaries within a concept space that delineate a given concept

### Description

Concept drift is the gradual warping of the meaning of a given concept over time. In a statistical learning context, the statistical properties of a target variable to be predicted, changes in unforeseen ways over time ([Gama et al. 2004](http://dblp.uni-trier.de/db/conf/sbia/sbia2004.html#GamaMCR04)), and robust AI should be vigilant in detecting such drift.

### Related Nodes

- [Robustness to Distributional Shift](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Uncertainty_Identification_and_Management/Inductive_Ambiguity_Identification/Robustness_to_Distributional_Shift/Robustness_to_Distributional_Shift.md)
	- Reason: From Concept Drift also see Robustness to Distributional Shift which addresses identifying and responding to increases in ambiguity around a concept statistically.
