### Mini Description

Recognizing when there is uncertainty around a concept or determination

### Description

There are many types of uncertainty that AIs will need to model ([Soares and Fallenstein 2014a](http://intelligence.org/files/TechnicalAgenda.pdf), [Carleton et al. 2007](https://www.aaai.org/Papers/Symposia/Spring/2008/SS-08-03/SS08-03-002.pdf)). As a matter of course, given their training data, machine learning deals with inductive uncertainty in typically narrow contexts. Awareness that insufficient traing data may have been provided for particular determinations supports the developing capability of recognizing ambiguity. Relatedly, determining dimensions or features for which there is little or no data, and which may be important, can be important for proactive ambiguity management ([Soares 2016](https://intelligence.org/files/ValueLearningProblem.pdf)). This is particularly relevant in online learning, where training is always incomplete and actions may be taken to focus on improving areas of unclarity ([Shalev-Shwartz 2012](http://www.cs.huji.ac.il/~shais/papers/OLsurvey.pdf)). At any given point in time, there may properly be not only inductive uncertainty regarding empirical facts, but also logical uncertainty, being unsure of the as-yet-to-be-computed specific complex entailments of the things that are already known ([Garrabrant et al. 2016a](https://intelligence.org/files/LogicalInductionAbridged.pdf)).

### Related Nodes

- [Value Specification](/Value_Alignment/Validation/Technical_Value_Alignment/Ethics_Mechanisms/Value_Specification/Value_Specification.md)
