### Mini Description

Techniques to adapt to changes to which inputs or parameters affect predictions and their weights in doing so

### Description

When the distribution of the inputs used as predictors changes between the training and the testing or production stages, covariate shift analysis can inform as to the extent ([Amodei et al. 2016](http://arxiv.org/abs/1606.06565)). For well-specified models, online-learning retunings to parameters or to sample weights can be appropriate ([Amodei et al. 2016](http://arxiv.org/abs/1606.06565)). For highly expressive model families, though some work has been done, there still needs more exploration to see how well they can predict their out-of-sample performance ([Hofmann et al. 2008](http://www.kernel-machines.org/publications/pdfs/0701907.pdf), [Solomonoff 1964](http://www.sciencedirect.com/science/article/pii/S0019995864902232/pdf?md5=528dcc7a51a90f7254fe06f76ea5f007&pid=1-s2.0-S0019995864902232-main.pdf), [Solomonoff 1964a](http://www.sciencedirect.com/science/article/pii/S0019995864901317), [Graves et al. 2014](https://pdfs.semanticscholar.org/6eed/f0a4fe861335f7f7664c14de7f71c00b7932.pdf), [Kaiser and Sutskever 2015a](http://arxiv.org/abs/1511.08228), [Osband et al. 2016](http://papers.nips.cc/paper/6500-deep-exploration-via-bootstrapped-dqn.pdf), [Bertsimas et al. 2011](https://faculty.fuqua.duke.edu/~dbbrown/bio/papers/bertsimas_brown_caramanis_11.pdf)). The sample selection bias may also be able to be leveraged to this end ([Chen et al. 2016](http://dblp.uni-trier.de/db/conf/aistats/aistats2016.html#ChenMLZ16)).
