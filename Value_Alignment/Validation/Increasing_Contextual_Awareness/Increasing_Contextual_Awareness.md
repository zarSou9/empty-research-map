### Mini Description

Techniques to reduce the contextual obliviousness that narrow modern-day AI systems often have

### Description

Whether using closed-world or open-world models, systems operating within the real world tend to model only a very small portion of the environment, rendering them oblivious to common sense contextualization of even concepts within their models. Such models also often have unintended structural biases and blind spots stemming from how they are generated, and reduction of this obliviousness leads to more trustworthy systems. With improved quality, salience, robustness, flexibility, and contextualization of conceptual models, agents can apply more common sense to introspection and to decision making. Typical ability gaps relative to humans include common sense context, learning causal models, the grounding of concepts, and learning to learn ([Lake et al. 2016](http://www.mit.edu/~tomeru/papers/machines_that_think.pdf), [Thorisson et al. 2016a](http://dx.doi.org/10.1007/978-3-319-41649-6_11)), despite experimental systems having demonstrated each of these individually.

### Related Nodes

- [Theory of Counterfactuals](/Value_Alignment/Foundations/Foundations_of_Rational_Agency/Theory_of_Counterfactuals/Theory_of_Counterfactuals.md)
- [Rich Understanding of Human Commands](/Value_Alignment/Control/Oversight/Rich_Understanding_of_Human_Commands/Rich_Understanding_of_Human_Commands.md)
