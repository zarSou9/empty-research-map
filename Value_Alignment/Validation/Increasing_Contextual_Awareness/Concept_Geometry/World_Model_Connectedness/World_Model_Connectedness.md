### Mini Description

Motivations and techniques to reduce the fragmentation within an ontology

### Description

Fragmented world models occur when portions of an (explicit or implicit) ontology that, environmentally, should connect or overlap, remain cleaved. This can lead to limited causal learning, inconsistent theories, unwarranted concept splitting, and poor transfer learning ([Pan and Yang 2010](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf), Mallah 2017). Fragmentation can also result in catastrophic inference, orphaning historical representations ([Nikolic 2014](http://ac.els-cdn.com/S002251931500106X/1-s2.0-S002251931500106X-main.pdf?_tid=6f1c2bc8-c4e7-11e6-972c-00000aacb35e&acdnat=1482041076_291e3fa094036bcad0f5601cfc975933), [French 1993](https://papers.nips.cc/paper/799-catastrophic-interference-in-connectionist-networks-can-it-be-predicted-can-it-be-prevented.pdf)). Focus on establishing explicit connections across contexts to previously learned features might alleviate these issues ([Rusu et al. 2016](https://arxiv.org/pdf/1606.04671v3)).

### Related Nodes

- [Unsupervised Model Learning](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Realistic_World-Models/Unsupervised_Model_Learning/Unsupervised_Model_Learning.md)
- [Perceptual Distance Agnostic World Models](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Realistic_World-Models/Perceptual_Distance_Agnostic_World_Models/Perceptual_Distance_Agnostic_World_Models.md)
