### Mini Description

Methods to represent normal variation within a concept but not potential extreme outliers

### Description

How can a classifier be trained to develop useful concepts that exclude quite atypical examples and edge cases? ([Taylor et al. 2016](https://intelligence.org/files/AlignmentMachineLearning.pdf)) Including negative examples to try to get a better sense of the classification boundaries is insufficient ([Goodfellow et al. 2015](https://pdfs.semanticscholar.org/bee0/44c8e8903fb67523c1f8c105ab4718600cdb.pdf), [Siddiqui et al. 2016](http://auai.org/uai2016/proceedings/papers/226.pdf)). Novel ways of analyzing cluster spaces may be necessary.

### Related Nodes

- [Generative Adversarial Networks](/Value_Alignment/Validation/Technical_Value_Alignment/Robust_Human_Imitation/Imitation_Statistical_Guarantees/Generative_Adversarial_Networks/Generative_Adversarial_Networks.md)
	- Reason: From Conservative Concepts also see Generative Adversarial Networks as actor-critic arrangements can refine the understanding of a concept, though more research needs to be done to scale the generalizations by the critic.
- [Goal Stability](/Value_Alignment/Foundations/Consistent_Decision_Making/Goal_Stability/Goal_Stability.md)
	- Reason: From Conservative Concepts also see Goal Stability as outlandish interpretations of concepts hamper stability.
- [Inductive Ambiguity Identification](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Uncertainty_Identification_and_Management/Inductive_Ambiguity_Identification/Inductive_Ambiguity_Identification.md)
	- Reason: From Conservative Concepts also see Inductive Ambiguity Identification as those techniques can be used to better analyze decision boundary neighborhoods and generated exemplars.
