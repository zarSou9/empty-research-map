### Mini Description

Methods for disentangling correlation from causation to clarify explanations generated by AI

### Description

Automated reports that attempt to explain events often report on the correlations or covariances among different factors or features. Methods for disentangling correlation from causation, however, can clarify AI-generated explanations. When world models are too small or inadequately structured, it may not be possible. Work on generalizing the bounds in which one can isolate the effects of an action may be useful in wider use of such techniques (Shalit et al. 2016).

### Related Nodes

- [Causal Identification](/Value_Alignment/Validation/Increasing_Contextual_Awareness/Uncertainty_Identification_and_Management/Inductive_Ambiguity_Identification/Robustness_to_Distributional_Shift/Causal_Identification/Causal_Identification.md)
	- Reason: From Causal Accounting also see Causal Identification which addresses causal disentanglement for purposes of the agent's understanding, but which can also be leveraged for monitoring by operators.
