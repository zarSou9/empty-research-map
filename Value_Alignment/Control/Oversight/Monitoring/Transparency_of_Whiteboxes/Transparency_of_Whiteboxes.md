### Mini Description

Methods by which algorithms can be more transparent to introspection and understandability

### Description

Whitebox algorithms, which are amenable to introspection, each have respective methods by which algorithms can be more transparent to introspection and understandability ([Taylor et al. 2016](https://intelligence.org/files/AlignmentMachineLearning.pdf)), including more explicitly interpretable models such as bayesian networks, causal networks, and rule lists ([Friedman et al. 1997](http://dx.doi.org/10.1023/A:1007465528199), [Pearl 2009](http://bayes.cs.ucla.edu/BOOK-2K/), [Weber et al. 2012](http://dx.doi.org/10.1016/j.engappai.2010.06.002), [Carmona and Riedel 2015](http://ceur-ws.org/Vol-1583/CoCoNIPS_2015_paper_10.pdf), [Janzing et al. 2013](http://dx.doi.org/10.1214/13-AOS1145), [Letham et al. 2015](http://dx.doi.org/10.1214/15-AOAS848), [Core et al. 2006](http://www.aaai.org/Papers/IAAI/2006/IAAI06-010.pdf), [Gallego-Ortiz and Martel 2016](https://pdfs.semanticscholar.org/748d/3ef9f05b3c95cf82a14aa64549bcbe94be60.pdf)), and even less typically-interpretable algorithms such as graphical models and dimensionality reduction ([Vellido et al. 2012](https://pdfs.semanticscholar.org/ce0b/8b6fca7dc089548cc2e9aaac3bae82bb19da.pdf), Maaten and E. 2008, [Condry 2016](https://arxiv.org/pdf/1607.00279.pdf)). Techniques like listing an agent's most likely next actions ([Thomaz and Breazeal 2006](http://www.cc.gatech.edu/~athomaz/papers/ThomazBreazeal-ICDL06.pdf), [Li et al. 2013](http://dl.acm.org/citation.cfm?id=2484920.2485064)), summarizing its upcoming possible future states ([Bai et al. 2016](http://www.ijcai.org/Abstract/16/430)), interactive behavior introspection and exploration ([Ko and Myers 2004](http://www.cs.cmu.edu/~ajko/papers/Ko2004Whyline.pdf), [Siddiqui et al. 2015](https://pdfs.semanticscholar.org/cb15/e3855bb420a7a73eadb0c4d38fd1095dc209.pdf), [Kulesza et al. 2015](ftp://ftp.cs.orst.edu/pub/burnett/iui15-elucidebug.pdf), [Ko and Myers 2009](http://repository.cmu.edu/cgi/viewcontent.cgi?article=1163&context=hcii), [Lane et al. 2005](http://ict.usc.edu/pubs/Explainable%20Artificial%20Intelligence%20for%20Training%20and%20Tutoring.pdf), [Brooks et al. 2010](http://www.aaai.org/ocs/index.php/FSS/FSS10/paper/viewFile/2223/2749)), and generating narrative explanations of decisions ([Biran and McKeown 2014](http://www.cs.columbia.edu/~orb/papers/justification_automl_2014.pdf)) all support this type of transparency, and can potentially be used in conjunction. The understanding and visualization of representations learned by neural networks is both a large need for the increasingly popular and powerful deep learning techniques and has a growing set of proposed solutions ([Simonyan et al. 2013](http://www.robots.ox.ac.uk/~vgg/publications/2014/Simonyan14a/simonyan14a.pdf), [Zeiler and Fergus 2014](http://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf), [Mordvintsev et al. 2015](https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html), [Mahendran and Vedaldi 2015](https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/mahendran15understanding.pdf), [Goodfellow et al. 2015](https://pdfs.semanticscholar.org/bee0/44c8e8903fb67523c1f8c105ab4718600cdb.pdf), [Karpathy 2015a](http://cs231n.github.io/understanding-cnn/), [Krakovna and Doshi-Velez 2016](https://pdfs.semanticscholar.org/d512/e36d361d313cae20c9766fedd6f84c71f09c.pdf), [Olah 2015](http://colah.github.io/posts/2015-01-Visualizing-Representations/), [Nguyen et al. 2016](https://papers.nips.cc/paper/6519-synthesizing-the-preferred-inputs-for-neurons-in-neural-networks-via-deep-generator-networks.pdf), [Carmantini et al. 2016](http://arxiv.org/abs/1609.01926)). When trying to understand complex deep learning systems, generating visualizations or exemplars that accentuate particular parts of a the deep network that are particularly relevant for the classification ([Simonyan et al. 2013](http://www.robots.ox.ac.uk/~vgg/publications/2014/Simonyan14a/simonyan14a.pdf), [Zeiler and Fergus 2014](http://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)) can be useful.
