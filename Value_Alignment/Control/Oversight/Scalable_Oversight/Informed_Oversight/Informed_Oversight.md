### Mini Description

Asking a relatively powerful and well-informed principal to incentivize good behavior from a weaker and more ignorant agent

### Description

In oversight scenarios like the approval directed agent paradigm, the more powerful and well-informed principal agent will need to find ways to incentivize good behavior from the weaker and more ignorant agent that the more capable one would like to teach ([Christiano 2016e](https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35), [Jessica 2016](https://agentfoundations.org/item?id=700)). Underexplored as yet are the problems of informed oversight that come about when the system is highly capable and might be able to manipulate its human supervisors or circumvent their efforts ([Taylor et al. 2016](https://intelligence.org/files/AlignmentMachineLearning.pdf)). Determining what sort of guarantees one should want in order to justify confidence in their ability to assess a systems behavior in the first place would be useful to provide next research steps on the theoretical side ([Taylor et al. 2016](https://intelligence.org/files/AlignmentMachineLearning.pdf)).

### Related Nodes

- [Technical Value Alignment](/Value_Alignment/Validation/Technical_Value_Alignment/Technical_Value_Alignment.md)
- [Monitoring](/Value_Alignment/Control/Oversight/Monitoring/Monitoring.md)
	- Reason: From Informed Oversight also see Monitoring which provides key ways for the operator to be informed.
- [Transparent Reinforcement Learners](/Value_Alignment/Control/Oversight/Monitoring/Transparency_of_Whiteboxes/Transparent_Reinforcement_Learners/Transparent_Reinforcement_Learners.md)
	- Reason: From Informed Oversight also see Transparent Reinforcement Learners as sufficiently transparent RL might open practical approaches to informed oversight.
